{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "def create_features(df, is_training=True):\n",
    "    \"\"\"\n",
    "    Create optimized feature set\n",
    "    \"\"\"\n",
    "    # Time features\n",
    "    df['trans_datetime'] = pd.to_datetime(df['trans_date'] + ' ' + df['trans_time'])\n",
    "    df['trans_hour'] = df['trans_datetime'].dt.hour\n",
    "    df['trans_day'] = df['trans_datetime'].dt.day\n",
    "    \n",
    "    # Age calculation\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['age'] = df['trans_datetime'].dt.year - df['dob'].dt.year\n",
    "    df['age'] -= ((df['trans_datetime'].dt.month < df['dob'].dt.month) |\n",
    "                  ((df['trans_datetime'].dt.month == df['dob'].dt.month) &\n",
    "                   (df['trans_datetime'].dt.day < df['dob'].dt.day))).astype(int)\n",
    "    \n",
    "    # Category encoding\n",
    "    le = LabelEncoder()\n",
    "    df['category_code'] = le.fit_transform(df['category'])\n",
    "    \n",
    "    # Gender encoding\n",
    "    df['gender'] = (df['gender'] == 'M').astype(int)\n",
    "    \n",
    "    # Select final features\n",
    "    selected_features = [\n",
    "        'amt', 'trans_hour', 'trans_day', 'age', \n",
    "        'category_code', 'gender'\n",
    "    ]\n",
    "    \n",
    "    return df[selected_features]\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Prepare features\n",
    "print(\"Preparing features...\")\n",
    "X = create_features(train)\n",
    "y = train['is_fraud']\n",
    "\n",
    "# Scale features\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create pipeline with SMOTE and RandomForest\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42, sampling_strategy=0.3)),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=220,\n",
    "        random_state=42,\n",
    "        class_weight=None,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "print(\"Performing cross-validation...\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, X_scaled, y, scoring='f1', cv=cv)\n",
    "\n",
    "print(\"Cross-validation F1 scores:\", cv_scores)\n",
    "print(\"Average F1 score: {:.4f} (+/- {:.4f})\".format(\n",
    "    cv_scores.mean(), cv_scores.std() * 2))\n",
    "\n",
    "# Train final model\n",
    "print(\"Training final model...\")\n",
    "pipeline.fit(X_scaled, y)\n",
    "\n",
    "# Process test data and make predictions\n",
    "print(\"Processing test data and making predictions...\")\n",
    "X_test = create_features(test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "test_predictions = pipeline.predict(X_test_scaled)\n",
    "\n",
    "# Create submission file\n",
    "print(\"Creating submission file...\")\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'is_fraud': test_predictions\n",
    "})\n",
    "submission.to_csv('submission_rf_smote.csv', index=False)\n",
    "\n",
    "# Print prediction distribution\n",
    "print(\"\\nPrediction distribution in test set:\")\n",
    "print(pd.Series(test_predictions).value_counts(normalize=True))\n",
    "\n",
    "# Print feature importance\n",
    "print(\"\\nFeature importance:\")\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': pipeline.named_steps['classifier'].feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(importance_df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
